{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b01cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, TimeDistributed, Masking\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb905e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams[\"figure.figsize\"] = (20,12)\n",
    "figure(figsize=(100, 80), dpi=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67692258",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f5ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"diputacion_processed_data.h5\",\"r\")\n",
    "scaled_X = ma.array(f[\"scaled_x\"])\n",
    "scaled_X.mask = ma.array(f[\"x_mask\"])\n",
    "minX = np.array(f[\"minX\"])\n",
    "maxX = np.array(f[\"maxX\"])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979aa764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_scaler(scaled_x,minX,maxX):\n",
    "    return scaled_x*maxX-minX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c456e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scaled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionSet(test_fraction, data, partitions):\n",
    "    lenX = len(data)\n",
    "    test_size = int(len(data) * test_fraction)\n",
    "    test_df = data[int((partitions/100)*lenX):int((partitions/100)*lenX)+test_size]\n",
    "    train_df = ma.vstack((data[:int((partitions/100)*lenX)-1],data[int((partitions/100)*lenX)+test_size:]))\n",
    "    train_df[int((partitions/100)*lenX)] = ma.masked\n",
    "    return train_df, test_df\n",
    "\n",
    "train_dataf = []\n",
    "test_dataf = []\n",
    "\n",
    "partitions=75\n",
    "\n",
    "for i in range(1, partitions):\n",
    "    [train_df,test_df] = partitionSet(0.25,scaled_X,i)\n",
    "    train_dataf.append(train_df)\n",
    "    test_dataf.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bfb983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset(train, test, timesteps):\n",
    "    X_train = ma.array([train[t:t+timesteps] for t in range(0,len(train)-timesteps)])\n",
    "    y_train = train[timesteps:, :]\n",
    "    X_test = ma.array([test[t:t+timesteps] for t in range(0,len(test)-timesteps)])\n",
    "    y_test = test[timesteps:, :]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "train_X_data = []\n",
    "train_Y_data = []\n",
    "test_X_data = []\n",
    "test_Y_data = []\n",
    "\n",
    "\n",
    "for j in range(0, len(train_dataf)):\n",
    "    [train_X_dates,train_Y_dates,test_X_dates,test_Y_dates]=Dataset(train_dataf[j],test_dataf[j], 24)\n",
    "    train_X_data.append(train_X_dates)\n",
    "    train_Y_data.append(train_Y_dates)\n",
    "    test_X_data.append(test_X_dates)\n",
    "    test_Y_data.append(test_Y_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_X_data.npy', 'wb') as f:\n",
    "    np.save(f, [train_X_data[i] for i in range(0, len(train_dataf))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbb2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_Y_data.npy', 'wb') as f:\n",
    "    np.save(f, [train_Y_data[i] for i in range(0, len(train_dataf))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_X_data.npy', 'wb') as f:\n",
    "    np.save(f, [test_X_data[i] for i in range(0, len(train_dataf))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_Y_data.npy', 'wb') as f:\n",
    "    np.save(f, [test_Y_data[i] for i in range(0, len(train_dataf))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f3a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782316dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience=6, min_delta=0.00001, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_function(NCells, timesteps, num_features, dropout, NBEpochs, Batchsize, validationSplit, earlystopping, i):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=(timesteps, num_features)))\n",
    "    model.add(LSTM(1, activation = 'tanh', input_shape = (timesteps, num_features), return_sequences=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(NCells))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss = 'mse', optimizer='adam')\n",
    "    X_ = ma.filled(train_X_data[i],0)\n",
    "    Y_ = ma.filled(train_Y_data[i],0)\n",
    "    MODEL = model.fit(X_, Y_, epochs = NBEpochs, batch_size = Batchsize,\n",
    "                      validation_split = validationSplit, shuffle = False,\n",
    "                      callbacks=[earlystopping])\n",
    "    return model, MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5467476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = []\n",
    "df_validation = []\n",
    "models = []\n",
    "MODELS = []\n",
    "\n",
    "datasets = np.arange(0,partitions-1)\n",
    "\n",
    "for j in datasets:\n",
    "    [model, MODEL] = LSTM_function(50,np.shape(train_X_data[0])[1], 1, 0.2, 200, 100, 0.2, early_stopping, j)\n",
    "    df_train.append(MODEL.history['loss'])\n",
    "    df_validation.append(MODEL.history['val_loss'])\n",
    "    models.append(model)\n",
    "    MODELS.append(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f36ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datasets:\n",
    "    models[i].save('/home/costa/Institute/ModelsForAlicante/Diputacion/models/DiputacionModel'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_performance = []\n",
    "for i in datasets:\n",
    "    train_performance.append(np.array(df_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e34646",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = []\n",
    "for i in datasets:\n",
    "    val_performance.append(np.array(df_validation[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_performance.npy', 'wb') as f:\n",
    "    np.save(f, [train_performance[i] for i in datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e66c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_performance.npy', 'wb') as f:\n",
    "    np.save(f, [val_performance[i] for i in datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4329872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #python regular expression matching module\n",
    "script = re.sub(r'# In\\[.*\\]:\\n','',open('3.0-Model.py').read())\n",
    "with open('3.0-ModelScript.py','w') as fh:\n",
    "    fh.write(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476c206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
